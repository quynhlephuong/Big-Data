{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0Z_RulxQR0B"
      },
      "source": [
        "# Cài đặt Apache Spark & Java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-0kdQ3RP1ww",
        "outputId": "a0269c99-3e4d-4a07-b829-690b90b5906c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 371M Jun 19  2023 spark-3.4.1-bin-hadoop3.tgz\n",
            "total 156\n",
            "drwxr-xr-x 2 1000 1000  4096 Jun 19  2023 bin\n",
            "drwxr-xr-x 2 1000 1000  4096 Jun 19  2023 conf\n",
            "drwxr-xr-x 5 1000 1000  4096 Jun 19  2023 data\n",
            "drwxr-xr-x 4 1000 1000  4096 Jun 19  2023 examples\n",
            "drwxr-xr-x 2 1000 1000 20480 Jun 19  2023 jars\n",
            "drwxr-xr-x 4 1000 1000  4096 Jun 19  2023 kubernetes\n",
            "-rw-r--r-- 1 1000 1000 22982 Jun 19  2023 LICENSE\n",
            "drwxr-xr-x 2 1000 1000  4096 Jun 19  2023 licenses\n",
            "-rw-r--r-- 1 1000 1000 57842 Jun 19  2023 NOTICE\n",
            "drwxr-xr-x 9 1000 1000  4096 Jun 19  2023 python\n",
            "drwxr-xr-x 3 1000 1000  4096 Jun 19  2023 R\n",
            "-rw-r--r-- 1 1000 1000  4605 Jun 19  2023 README.md\n",
            "-rw-r--r-- 1 1000 1000   165 Jun 19  2023 RELEASE\n",
            "drwxr-xr-x 2 1000 1000  4096 Jun 19  2023 sbin\n",
            "drwxr-xr-x 2 1000 1000  4096 Jun 19  2023 yarn\n"
          ]
        }
      ],
      "source": [
        "# Cài Java\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Xoá các file .tgz cũ (nếu có) để tránh trùng tên\n",
        "!rm -f spark-3.4.1-bin-hadoop3.tgz*\n",
        "\n",
        "# Tải Spark bản 3.4.1 ổn định\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.4.1/spark-3.4.1-bin-hadoop3.tgz\n",
        "\n",
        "# Kiểm tra file vừa tải\n",
        "!ls -lh spark-3.4.1-bin-hadoop3.tgz\n",
        "\n",
        "# Giải nén Spark\n",
        "!tar -xzf spark-3.4.1-bin-hadoop3.tgz\n",
        "\n",
        "# Kiểm tra thư mục sau khi giải nén\n",
        "!ls -l spark-3.4.1-bin-hadoop3\n",
        "\n",
        "# Cài findspark để khởi tạo Spark trong Python\n",
        "!pip install -q findspark\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LZF7FbsSAn8"
      },
      "source": [
        "# Cấu hình môi trường & Khởi tạo SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v62p4IJRnlW",
        "outputId": "c8707cff-75c9-4386-cf96-ce5e5b651d6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark version: 3.4.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import findspark\n",
        "\n",
        "# Cấu hình biến môi trường\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.4.1-bin-hadoop3\"\n",
        "\n",
        "# Khởi tạo findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Tạo SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"FraudDetectionDemo\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Kiểm tra SparkSession\n",
        "print(\"Spark version:\", spark.version)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHvkpcv4SsHy"
      },
      "source": [
        "# Tải dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rww1JGV4SpaY",
        "outputId": "dc0706ef-e268-4b40-bd85-c4f3e2a1d9d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mn1i7orS8fu"
      },
      "source": [
        "# Đọc dữ liệu vào Spark DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQ5RHGGtVFFd",
        "outputId": "df4f260d-c468-473a-afa4-000f59159252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- step: integer (nullable = true)\n",
            " |-- type: string (nullable = true)\n",
            " |-- amount: double (nullable = true)\n",
            " |-- nameOrig: string (nullable = true)\n",
            " |-- oldbalanceOrg: double (nullable = true)\n",
            " |-- newbalanceOrig: double (nullable = true)\n",
            " |-- nameDest: string (nullable = true)\n",
            " |-- oldbalanceDest: double (nullable = true)\n",
            " |-- newbalanceDest: double (nullable = true)\n",
            " |-- isFraud: integer (nullable = true)\n",
            " |-- isFlaggedFraud: integer (nullable = true)\n",
            "\n",
            "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
            "|step|    type|  amount|   nameOrig|oldbalanceOrg|newbalanceOrig|   nameDest|oldbalanceDest|newbalanceDest|isFraud|isFlaggedFraud|\n",
            "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
            "|   1| PAYMENT| 9839.64|C1231006815|     170136.0|     160296.36|M1979787155|           0.0|           0.0|      0|             0|\n",
            "|   1| PAYMENT| 1864.28|C1666544295|      21249.0|      19384.72|M2044282225|           0.0|           0.0|      0|             0|\n",
            "|   1|TRANSFER|   181.0|C1305486145|        181.0|           0.0| C553264065|           0.0|           0.0|      1|             0|\n",
            "|   1|CASH_OUT|   181.0| C840083671|        181.0|           0.0|  C38997010|       21182.0|           0.0|      1|             0|\n",
            "|   1| PAYMENT|11668.14|C2048537720|      41554.0|      29885.86|M1230701703|           0.0|           0.0|      0|             0|\n",
            "+----+--------+--------+-----------+-------------+--------------+-----------+--------------+--------------+-------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/Paysim.csv\"\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "df.printSchema()\n",
        "df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba5GKqy7TFtl"
      },
      "source": [
        "# Tạo cột phân nhóm gian lận"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVmlbsGNcwTW"
      },
      "source": [
        "Hệ thống gán nhãn gian lận (flag)\n",
        "\n",
        "G1: Giao dịch isFraud = 1 và isFlaggedFraud = 1 → Flag đúng.\n",
        "\n",
        "G2: Giao dịch isFraud = 1 và isFlaggedFraud = 0 → Bỏ sót.\n",
        "\n",
        "G3: Giao dịch isFraud = 0 và isFlaggedFraud = 1 → Flag nhầm.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIRGvkbXTE4L",
        "outputId": "9fb26f27-69cc-454b-afd4-b05337b3c8a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------+---------------+\n",
            "|isFraud|isFlaggedFraud|    fraud_group|\n",
            "+-------+--------------+---------------+\n",
            "|      0|             0|    Bình thường|\n",
            "|      0|             0|    Bình thường|\n",
            "|      1|             0|Bỏ sót gian lận|\n",
            "|      1|             0|Bỏ sót gian lận|\n",
            "|      0|             0|    Bình thường|\n",
            "|      0|             0|    Bình thường|\n",
            "|      0|             0|    Bình thường|\n",
            "|      0|             0|    Bình thường|\n",
            "|      0|             0|    Bình thường|\n",
            "|      0|             0|    Bình thường|\n",
            "+-------+--------------+---------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import when, col\n",
        "\n",
        "df = df.withColumn(\"fraud_group\",\n",
        "    when((col(\"isFraud\") == 1) & (col(\"isFlaggedFraud\") == 1), \"Gian lận đúng flag\")\n",
        "    .when((col(\"isFraud\") == 1) & (col(\"isFlaggedFraud\") == 0), \"Bỏ sót gian lận\")\n",
        "    .when((col(\"isFraud\") == 0) & (col(\"isFlaggedFraud\") == 1), \"Flag sai\")\n",
        "    .otherwise(\"Bình thường\")\n",
        ")\n",
        "\n",
        "df.select(\"isFraud\", \"isFlaggedFraud\", \"fraud_group\").show(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7HkHtV-WCSI"
      },
      "source": [
        "# So sánh đặc trưng giữa ba nhóm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWekJKLRWC7C",
        "outputId": "8486164d-d34e-4085-c44d-c25b9d56dc3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|    type|count|\n",
            "+--------+-----+\n",
            "|TRANSFER|  578|\n",
            "|CASH_OUT|  599|\n",
            "+--------+-----+\n",
            "\n",
            "+---------------+--------+------+\n",
            "|    fraud_group|    type| count|\n",
            "+---------------+--------+------+\n",
            "|       Flag sai|CASH_OUT|     4|\n",
            "|Bỏ sót gian lận|CASH_OUT|   599|\n",
            "|Bỏ sót gian lận|TRANSFER|   578|\n",
            "|    Bình thường|CASH_OUT|373066|\n",
            "|    Bình thường| PAYMENT|353807|\n",
            "|    Bình thường| CASH_IN|227128|\n",
            "|    Bình thường|TRANSFER| 86218|\n",
            "|    Bình thường|   DEBIT|  7175|\n",
            "+---------------+--------+------+\n",
            "\n",
            "+---------------+------------------+\n",
            "|    fraud_group|       avg(amount)|\n",
            "+---------------+------------------+\n",
            "|    Bình thường| 157542.1819822183|\n",
            "|Bỏ sót gian lận|1157280.1532965186|\n",
            "|       Flag sai|            5000.0|\n",
            "+---------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "\n",
        "# Loại giao dịch không bao giờ gian lận\n",
        "df.filter(col(\"isFraud\") == 1).groupBy(\"type\").count().show()\n",
        "\n",
        "\n",
        "# Thống kê số lượng giao dịch theo nhóm gian lận và loại giao dịch\n",
        "count_by_type = df.groupBy(\"fraud_group\", \"type\").count().orderBy(\"fraud_group\", \"count\", ascending=False)\n",
        "count_by_type.show(20)\n",
        "\n",
        "# Tính tiền trung bình theo nhóm gian lận\n",
        "avg_amount = df.groupBy(\"fraud_group\").avg(\"amount\")\n",
        "avg_amount.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxSK3dpci1BO"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-soSbcWjDId"
      },
      "source": [
        "Xây dựng một pipeline ML hoàn chỉnh từ tiền xử lý (chuyển đổi biến), tạo vector đặc trưng, huấn luyện mô hình Random Forest, dự đoán và đánh giá hiệu suất mô hình\n",
        "\n",
        "=> Dự đoán xem một giao dịch có phải gian lận (fraud) hay không dựa trên các đặc trưng đầu vào.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL1UWMPaAF9C"
      },
      "source": [
        "ML:  Sử dụng tập dữ liệu mẫu (df_sample) để huấn luyện mô hình Random Forest (model) có khả năng phát hiện gian lận.\n",
        "\n",
        "Phát hiện và cảnh báo tài khoản có dấu hiệu gian lận: sử dụng mô hình  (`model`) để **dự đoán và phân tích rủi ro gian lận** trên toàn bộ tập dữ liệu (`df`),  đưa ra cảnh báo đối với những tài khoản có xác suất cao hoặc nhiều lần bị nghi ngờ gian lận.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVYlHOHL3C2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af3fcc41-a65d-42c2-eac5-0a0a9178477b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9981945170333064\n",
            "Precision: 0.9981572758566477\n",
            "Recall: 0.9981945170333064\n",
            "F1 Score: 0.9981451159075917\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.sql.functions import when, col, avg\n",
        "\n",
        "# Sample 10% dữ liệu gốc\n",
        "df_sample = df.sample(fraction=0.1, seed=42)\n",
        "\n",
        "\n",
        "# Oversample isFraud = 1 để dữ liệu cân bằng hơn\n",
        "fraud_df = df_sample.filter(col(\"isFraud\") == 1)\n",
        "nonfraud_df = df_sample.filter(col(\"isFraud\") == 0)\n",
        "fraud_df_oversampled = fraud_df.sample(withReplacement=True, fraction=10.0, seed=42)\n",
        "\n",
        "df_balanced = nonfraud_df.union(fraud_df_oversampled)\n",
        "\n",
        "# Tạo các đặc trưng hành vi vì các đặc trưng nguyên thủy (amount, oldbalanceOrg,...) không mô tả được hành vi\n",
        "\n",
        "df_balanced = df_balanced.withColumn(\"diff_balance_orig\", col(\"oldbalanceOrg\") - col(\"newbalanceOrig\")) #Tiền thật sự bị trừ\n",
        "df_balanced = df_balanced.withColumn(\"diff_balance_dest\", col(\"newbalanceDest\") - col(\"oldbalanceDest\")) #Tiền thực sự cộng vào\n",
        "df_balanced = df_balanced.withColumn(\"amount_ratio\", col(\"amount\") / (col(\"oldbalanceOrg\") + 1))  #Tỉ lệ tiền giao dịch\n",
        "\n",
        "# Chuyển cột 'type' sang số với StringIndexer\n",
        "type_indexer = StringIndexer(inputCol=\"type\", outputCol=\"typeIndex\")\n",
        "\n",
        "# Tạo các features\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\n",
        "        \"typeIndex\", \"amount\", \"oldbalanceOrg\", \"newbalanceOrig\",\n",
        "        \"oldbalanceDest\", \"newbalanceDest\", \"diff_balance_orig\",\n",
        "        \"diff_balance_dest\", \"amount_ratio\"\n",
        "    ],\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "# Chuyển nhãn 'isFraud' thành label\n",
        "label_indexer = StringIndexer(inputCol=\"isFraud\", outputCol=\"label\")\n",
        "\n",
        "# Khởi tạo Random Forest\n",
        "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees=50, maxDepth=10)\n",
        "\n",
        "# Tạo pipeline\n",
        "pipeline = Pipeline(stages=[type_indexer, assembler, label_indexer, rf])\n",
        "\n",
        "# Chia tập train/test\n",
        "train_df, test_df = df_balanced.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Huấn luyện mô hình\n",
        "model = pipeline.fit(train_df)\n",
        "\n",
        "# Dự đoán\n",
        "predictions = model.transform(test_df)\n",
        "\n",
        "# Đánh giá\n",
        "evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
        "evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
        "evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
        "\n",
        "accuracy = evaluator_acc.evaluate(predictions)\n",
        "precision = evaluator_precision.evaluate(predictions)\n",
        "recall = evaluator_recall.evaluate(predictions)\n",
        "f1 = evaluator_f1.evaluate(predictions)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3sVeg3lXBE-",
        "outputId": "54d38a2e-6387-4ebc-bd87-7b9e58383599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------------------+-------------------+------------------+\n",
            "|   nameOrig|    avg_fraud_prob|count_flagged_fraud|total_transactions|\n",
            "+-----------+------------------+-------------------+------------------+\n",
            "| C127639062|0.9984903947627225|                  2|                 2|\n",
            "| C874465366|0.9984903947627225|                  1|                 1|\n",
            "|C1267904754|0.9984903947627225|                  2|                 2|\n",
            "| C262990065|0.9984903947627225|                  3|                 3|\n",
            "| C365968372| 0.998279868446933|                  2|                 2|\n",
            "+-----------+------------------+-------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import avg, count, when, col\n",
        "\n",
        "# 1. Dự đoán cho toàn bộ dữ liệu (hoặc df_sample)\n",
        "predictions_all = model.transform(test_df)\n",
        "\n",
        "# 2. Lấy xác suất dự đoán gian lận (lấy cột 'probability' từ vector xác suất)\n",
        "# probability là Vector( [p(not_fraud), p(fraud)] ), ta lấy phần tử thứ 2\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "\n",
        "get_fraud_prob = udf(lambda v: float(v[1]), DoubleType())\n",
        "predictions_all = predictions_all.withColumn(\"fraud_prob\", get_fraud_prob(col(\"probability\")))\n",
        "\n",
        "# 3. Tổng hợp theo tài khoản nameOrig: trung bình xác suất gian lận, số lần dự đoán gian lận\n",
        "account_risk = predictions_all.groupBy(\"nameOrig\") \\\n",
        "    .agg(\n",
        "        avg(\"fraud_prob\").alias(\"avg_fraud_prob\"),\n",
        "        count(when(col(\"prediction\") == 1, True)).alias(\"count_flagged_fraud\"),\n",
        "        count(\"*\").alias(\"total_transactions\")\n",
        "    ) \\\n",
        "    .orderBy(col(\"avg_fraud_prob\").desc())\n",
        "\n",
        "\n",
        "# 4. Hiển thị 20 tài khoản đầu tiên theo mức độ rủi ro (dù có cảnh báo hay không)\n",
        "account_risk.show(5)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}